{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "25bac80c",
      "metadata": {},
      "source": [
        "# Adapter Demo: Training and Batched Inference\n",
        "\n",
        "This notebook demonstrates the multi-adapter LoRA workflow:\n",
        "1. **Training**: Register fresh adapters, train them on random data, save to disk\n",
        "2. **Inference**: Load adapters from disk and run batched inference with per-sample adapter selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "efbf500a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7d39a7f30e90>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.insert(0, \"src\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from pathlib import Path\n",
        "\n",
        "from adapter_manager import AdapterManager\n",
        "\n",
        "# Configuration\n",
        "VOCAB_SIZE = 1000\n",
        "HIDDEN_DIM = 64\n",
        "OUT_DIM = 32\n",
        "FINAL_DIM = 16\n",
        "R = 4\n",
        "ALPHA = 4\n",
        "BATCH_SIZE = 8\n",
        "SEQ_LEN = 16\n",
        "\n",
        "ADAPTERS_DIR = Path(\"./adapters\")\n",
        "ADAPTERS_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "cb0d9ccb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model architecture:\n",
            "Sequential(\n",
            "  (0): Embedding(1000, 64)\n",
            "  (1): BatchedLoRALinear(\n",
            "    (base): Linear(in_features=64, out_features=32, bias=True)\n",
            "  )\n",
            "  (2): ReLU()\n",
            "  (3): BatchedLoRALinear(\n",
            "    (base): Linear(in_features=32, out_features=16, bias=True)\n",
            "  )\n",
            ")\n",
            "LoRA layers injected: ['1', '3']\n"
          ]
        }
      ],
      "source": [
        "def create_model():\n",
        "    \"\"\"Create a simple model for demonstration.\"\"\"\n",
        "    return nn.Sequential(\n",
        "        nn.Embedding(VOCAB_SIZE, HIDDEN_DIM),\n",
        "        nn.Linear(HIDDEN_DIM, OUT_DIM),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(OUT_DIM, FINAL_DIM),\n",
        "    )\n",
        "\n",
        "# Create model and wrap with AdapterManager (injects BatchedLoRALinear layers)\n",
        "model = create_model()\n",
        "manager = AdapterManager(model, r=R, alpha=ALPHA, max_cache_entries=0)  # No cache for training\n",
        "\n",
        "print(\"Model architecture:\")\n",
        "print(model)\n",
        "print(f\"LoRA layers injected: {manager.lora_names}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c90dae0",
      "metadata": {},
      "source": [
        "## Part 1: Training Adapters\n",
        "\n",
        "We'll register 3 fresh adapters with default initialization and train them on random data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "39a6cc53",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Registered: adapter_1\n",
            "Registered: adapter_2\n",
            "Registered: adapter_3\n",
            "\n",
            "Total adapters: ['adapter_1', 'adapter_2', 'adapter_3']\n"
          ]
        }
      ],
      "source": [
        "# Register 3 fresh adapters (Kaiming init for A, zeros for B)\n",
        "adapter_names = [\"adapter_1\", \"adapter_2\", \"adapter_3\"]\n",
        "\n",
        "for name in adapter_names:\n",
        "    manager.register_new_adapter(name)\n",
        "    print(f\"Registered: {name}\")\n",
        "\n",
        "print(f\"\\nTotal adapters: {list(manager.registered_adapters.keys())}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3fb1e38a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch   0 | Loss: 1.0391\n",
            "Epoch  10 | Loss: 1.0388\n",
            "Epoch  20 | Loss: 1.0213\n",
            "Epoch  30 | Loss: 1.0138\n",
            "Epoch  40 | Loss: 1.0035\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "NUM_EPOCHS = 50\n",
        "NUM_BATCHES = 10\n",
        "\n",
        "# Set all adapters active for training\n",
        "manager.set_adapters(adapter_names)\n",
        "\n",
        "# Optimizer only trains LoRA parameters (base model is frozen)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "with manager.training_mode(adapter_names):\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        epoch_loss = 0.0\n",
        "        \n",
        "        for _ in range(NUM_BATCHES):\n",
        "            # Generate random data\n",
        "            x = torch.randint(0, VOCAB_SIZE, (BATCH_SIZE, SEQ_LEN))\n",
        "            # Random adapter assignment per sample\n",
        "            adapter_ids = [adapter_names[i % len(adapter_names)] for i in range(BATCH_SIZE)]\n",
        "            # Fake targets\n",
        "            targets = torch.randn(BATCH_SIZE, SEQ_LEN, FINAL_DIM)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            output = manager.forward_multi(x, adapter_ids)\n",
        "            loss = loss_fn(output, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Epoch {epoch:3d} | Loss: {epoch_loss / NUM_BATCHES:.4f}\")\n",
        "\n",
        "print(\"Training complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "2003aa3c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: adapters/adapter_1.safetensors\n",
            "Saved: adapters/adapter_2.safetensors\n",
            "Saved: adapters/adapter_3.safetensors\n",
            "Adapter files: [PosixPath('adapters/adapter_2.safetensors'), PosixPath('adapters/adapter_3.safetensors'), PosixPath('adapters/adapter_1.safetensors')]\n"
          ]
        }
      ],
      "source": [
        "# Save trained adapters to disk\n",
        "for name in adapter_names:\n",
        "    path = ADAPTERS_DIR / f\"{name}.safetensors\"\n",
        "    manager.save_adapter(name, str(path))\n",
        "    print(f\"Saved: {path}\")\n",
        "\n",
        "print(f\"Adapter files: {list(ADAPTERS_DIR.glob('*.safetensors'))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c6cfcd2",
      "metadata": {},
      "source": [
        "## Part 2: Batched Inference with Multiple Adapters\n",
        "\n",
        "Simulate a fresh start: create a new model and manager, load the saved adapters, and run batched inference with per-sample adapter selection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "c2d5093d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded: adapter_1 from adapters/adapter_1.safetensors\n",
            "Loaded: adapter_2 from adapters/adapter_2.safetensors\n",
            "Loaded: adapter_3 from adapters/adapter_3.safetensors\n",
            "Registered adapters: ['adapter_1', 'adapter_2', 'adapter_3']\n"
          ]
        }
      ],
      "source": [
        "# Create a fresh model (simulating loading from scratch)\n",
        "inference_model = create_model()\n",
        "inference_manager = AdapterManager(inference_model, r=R, alpha=ALPHA, max_cache_entries=100)\n",
        "\n",
        "# Load the 3 trained adapters from disk\n",
        "for name in adapter_names:\n",
        "    path = ADAPTERS_DIR / f\"{name}.safetensors\"\n",
        "    inference_manager.register_adapter(name, str(path))\n",
        "    print(f\"Loaded: {name} from {path}\")\n",
        "\n",
        "print(f\"Registered adapters: {list(inference_manager.registered_adapters.keys())}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "e19c0f23",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([6, 16])\n",
            "Adapter assignments: ['adapter_1', 'adapter_2', 'adapter_3', 'adapter_1', 'adapter_2', 'adapter_3']\n",
            "\n",
            "Output shape: torch.Size([6, 16, 16])\n",
            "Output dtype: torch.float32\n"
          ]
        }
      ],
      "source": [
        "# Batched inference with per-sample adapter selection\n",
        "batch_size = 6\n",
        "x = torch.randint(0, VOCAB_SIZE, (batch_size, SEQ_LEN))\n",
        "\n",
        "# Each sample uses a different adapter\n",
        "adapter_ids = [\"adapter_1\", \"adapter_2\", \"adapter_3\", \"adapter_1\", \"adapter_2\", \"adapter_3\"]\n",
        "\n",
        "print(f\"Input shape: {x.shape}\")\n",
        "print(f\"Adapter assignments: {adapter_ids}\")\n",
        "\n",
        "# Run batched inference - all samples processed in one forward pass\n",
        "with torch.no_grad():\n",
        "    outputs = inference_manager.forward_multi(x, adapter_ids)\n",
        "\n",
        "print(f\"\\nOutput shape: {outputs.shape}\")\n",
        "print(f\"Output dtype: {outputs.dtype}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f32e9fcf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Same input, different adapters:\n",
            "  adapter_1 output mean: -0.0764\n",
            "  adapter_2 output mean: -0.0836\n",
            "  adapter_3 output mean: -0.0771\n",
            "All outputs identical? False (expected: False)\n"
          ]
        }
      ],
      "source": [
        "# Verify that different adapters produce different outputs for the same input\n",
        "same_input = torch.randint(0, VOCAB_SIZE, (1, SEQ_LEN))\n",
        "\n",
        "with torch.no_grad():\n",
        "    out_1 = inference_manager.forward_multi(same_input.expand(3, -1), [\"adapter_1\", \"adapter_2\", \"adapter_3\"])\n",
        "\n",
        "print(\"Same input, different adapters:\")\n",
        "print(f\"  adapter_1 output mean: {out_1[0].mean().item():.4f}\")\n",
        "print(f\"  adapter_2 output mean: {out_1[1].mean().item():.4f}\")\n",
        "print(f\"  adapter_3 output mean: {out_1[2].mean().item():.4f}\")\n",
        "\n",
        "# Check that outputs differ\n",
        "all_same = torch.allclose(out_1[0], out_1[1]) and torch.allclose(out_1[1], out_1[2])\n",
        "print(f\"All outputs identical? {all_same} (expected: False)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b86b21eb",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook demonstrated:\n",
        "\n",
        "1. **Training workflow**:\n",
        "   - `register_new_adapter()` creates fresh adapters with Kaiming/zeros initialization\n",
        "   - `training_mode()` context manager handles weight syncing and cache management\n",
        "   - `save_adapter()` persists weights to safetensors format\n",
        "\n",
        "2. **Inference workflow**:\n",
        "   - `register_adapter()` loads adapters from disk\n",
        "   - `forward_multi()` runs batched inference with per-sample adapter selection\n",
        "   - Each sample can use a different adapter in the same batch (no adapter switching overhead)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
